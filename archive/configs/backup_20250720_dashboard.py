# dashboard.py
"""
×“×©×‘×•×¨×“ × ×™×”×•×œ - ×‘×•×˜ ××¡×—×¨ ××œ×’×•×¨×™×ª××™
×××©×§ ××©×ª××© ×‘×××¦×¢×•×ª Streamlit - ×’×¨×¡×” ××œ××” ×•××ª×•×§× ×ª
"""
import streamlit as st
import json
import os
import sys
import subprocess
import time
import hashlib
import glob
import atexit
import traceback
import sqlite3
import shutil
from datetime import datetime
from pathlib import Path

import pandas as pd
import plotly.express as px
import requests
import optuna
from streamlit_cookies_manager import EncryptedCookieManager

from src.utils import load_system_config, save_system_config

# --- ×”×’×“×¨×•×ª ×›×œ×œ×™×•×ª ---
# --- Cookie Manager ---
cookie_password = os.environ.get("COOKIE_ENCRYPTION_PASSWORD", "default_cookie_password")
cookies = EncryptedCookieManager(
    password=cookie_password,
)
if not cookies.ready():
    st.stop()

# --- ×¤×•× ×§×¦×™×•×ª ×¢×–×¨ ---

@st.cache_data
def load_training_summaries():
    """
    Load and parse the main and archived training summary JSON files, returning a pandas DataFrame.
    """
    try:
        config = load_system_config()
        model_dir = Path(config['system_paths']['champion_model']).parent
        archive_dir = model_dir / 'archive'
        main_summary_file = model_dir / 'training_summary.json'
        archived_summaries = sorted(glob.glob(str(archive_dir / 'training_summary.json.*')), reverse=True)

        summary_files = []
        if main_summary_file.exists():
            summary_files.append(str(main_summary_file))
        summary_files.extend(archived_summaries)

        rows = []
        for fpath_str in summary_files:
            fpath = Path(fpath_str)
            try:
                with open(fpath, encoding="utf-8") as f:
                    data = json.load(f)

                file_ts = data.get('training_run_timestamp')
                if not file_ts:
                    continue  # Skip if the essential timestamp is missing

                best_params = data.get('best_params', {})
                all_params = data.get('all_params', {})
                class_report = data.get('classification_report', {})
                
                row = {
                    'timestamp': pd.to_datetime(data.get('timestamp')).strftime('%Y-%m-%d %H:%M') if data.get('timestamp') else 'N/A',
                    'objective_function': data.get('objective_function'),
                    'optuna_scores': str(data.get('optuna_scores', 'N/A')),
                    'test_accuracy': data.get('test_accuracy'),
                    'file_ts': file_ts,
                    'recall_0': class_report.get('0', {}).get('recall'),
                    'precision_0': class_report.get('0', {}).get('precision'),
                    'f1_0': class_report.get('0', {}).get('f1-score'),
                    'support_0': class_report.get('0', {}).get('support'),
                    'recall_1': class_report.get('1', {}).get('recall'),
                    'precision_1': class_report.get('1', {}).get('precision'),
                    'f1_1': class_report.get('1', {}).get('f1-score'),
                    'support_1': class_report.get('1', {}).get('support'),
                }
                
                # ×”×•×¡×¤×ª ×”×¤×¨××˜×¨×™× ×¢× ×¡×™××•×Ÿ ××•×¤×˜×™××™×–×¦×™×”
                if all_params:
                    # ×× ×™×© all_params, ×”×©×ª××© ×‘×”×
                    for param_name, param_info in all_params.items():
                        value = param_info.get('value', 'N/A')
                        optimized = param_info.get('optimized', False)
                        
                        # ×¢×™×¦×•×‘ ×”×¢×¨×š ×‘×”×ª×× ×œ×¡×•×’
                        if param_name in ['threshold', 'risk_per_trade'] and isinstance(value, float):
                            formatted_value = f"{value*100:.2f}%"
                        else:
                            formatted_value = value
                        
                        # ×”×•×¡×¤×ª ×¡×™××•×Ÿ ××•×¤×˜×™××™×–×¦×™×”
                        if optimized:
                            row[param_name] = f"ğŸ”„ {formatted_value}"
                        else:
                            row[param_name] = f"âšª {formatted_value}"
                else:
                    # ×× ××™×Ÿ all_params, ×”×©×ª××© ×‘-best_params ×”×™×©×Ÿ
                    for k, v in best_params.items():
                        if k in ['threshold', 'risk_per_trade'] and isinstance(v, float):
                            row[k] = f"{v*100:.2f}%"
                        else:
                            row[k] = v
                rows.append(row)
            except (json.JSONDecodeError, KeyError, TypeError):
                # Silently skip corrupted or malformed summary files
                continue
                
        if rows:
            return pd.DataFrame(rows).fillna('N/A')
        else:
            return pd.DataFrame()
            
    except Exception as e:
        st.error(f"Error loading training summaries: {e}")
        return pd.DataFrame()

def set_rtl_layout():
    """Injects custom CSS to force RTL layout and fix pinned columns."""
    st.markdown(
        """
        <style>
        /* ========= General RTL Layout ========= */
        html, body, [class*="st-"] {
            direction: rtl !important;
            text-align: right !important;
        }
        .st-emotion-cache-16txtl3 { /* Expander header */
            text-align: right !important;
        }
        th, td { /* Table headers and cells */
            text-align: right !important;
            direction: rtl !important;
        }

        /* ========= Advanced Pinned Column Fix ========= */
        /* Find the container for the table cells */
        .st-emotion-cache-tcwslb {
            direction: ltr !important; /* Force LTR on the direct container */
        }
        /* Find the row container and reverse its element order */
        .st-emotion-cache-10trblm {
            display: flex !important;
            flex-direction: row-reverse !important;
        }
        /* Style the pinned (sticky) columns */
        div[data-testid="stDataFrameTable"] [data-sticky-td] {
            left: unset !important;
            right: 0 !important;
        }
        </style>
        """,
        unsafe_allow_html=True
    )

def show_alert(msg, type_='info'):
    """×¤×•× ×§×¦×™×” ×œ×”×¦×’×ª ×”×ª×¨××” ×‘×•×œ×˜×ª."""
    if type_ == 'success':
        st.success(msg)
    elif type_ == 'error':
        st.error(msg)
    elif type_ == 'warning':
        st.warning(msg)
    else:
        st.info(msg)

def run_and_stream_process(command, spinner_text):
    """××¨×™×¥ ×ª×”×œ×™×š ×•××–×¨×™× ××ª ×”×¤×œ×˜ ×©×œ×• ×‘×–××Ÿ ×××ª ×œ×“×©×‘×•×¨×“."""
    progress_bar = st.progress(0, text="××ª×—×™×œ...")
    log_content = ""
    
    with st.expander(f"×¦×¤×” ×‘×¤×œ×˜ ×”×—×™ ×©×œ: {spinner_text}", expanded=True):
        output_placeholder = st.code("", language='log')
        try:
            process = subprocess.Popen(
                command,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
                encoding='utf-8',
                errors='replace',
                bufsize=1,
                creationflags=subprocess.CREATE_NO_WINDOW if sys.platform == 'win32' else 0
            )
            
            st.session_state['last_process'] = process

            for i, line in enumerate(iter(process.stdout.readline, '')):
                log_content += line
                output_placeholder.code(log_content, language='log')
                # Improved progress bar logic for better UX
                progress = min(0.95, 0.05 + i * 0.0005) 
                progress_bar.progress(progress, text=f"{spinner_text} (××¢×‘×“ ×©×•×¨×” {i+1})...")

            process.wait()
            progress_bar.progress(1.0, text="×”×¡×ª×™×™×!")
            
            if process.returncode == 0:
                show_alert(f"×”×ª×”×œ×™×š '{' '.join(command)}' ×”×¡×ª×™×™× ×‘×”×¦×œ×—×”!", type_='success')
            else:
                show_alert(f"×”×ª×”×œ×™×š '{' '.join(command)}' × ×›×©×œ ×¢× ×§×•×“ ×©×’×™××” {process.returncode}.", type_='error')

        except FileNotFoundError:
            show_alert(f"×©×’×™××”: ×”×¤×§×•×“×” '{command[0]}' ×œ× × ××¦××”. ×•×“× ×©×”× ×ª×™×‘ × ×›×•×Ÿ.", type_='error')
            log_content += f"ERROR: Command not found: {command[0]}"
            output_placeholder.code(log_content, language='log')
            progress_bar.progress(1.0, text="× ×›×©×œ!")
        except Exception as e:
            show_alert(f"×©×’×™××” ×‘×”×¨×¦×ª ×”×ª×”×œ×™×š: {e}", type_='error')
            log_content += f"\n--- TRACEBACK ---\n{traceback.format_exc()}"
            output_placeholder.code(log_content, language='log')
            progress_bar.progress(1.0, text="× ×›×©×œ!")

def cleanup_processes():
    """×× ×§×” ×ª×”×œ×™×›×™× ×¤×ª×•×—×™× ×‘×¡×’×™×¨×ª ×”×“×©×‘×•×¨×“."""
    for key in ['api_process', 'agent_process', 'optuna_dashboard_proc']:
        proc = st.session_state.get(key)
        if proc and proc.poll() is None:
            try:
                proc.terminate()
                proc.wait(timeout=5)
            except Exception:
                pass
atexit.register(cleanup_processes)

def get_process_status(proc):
    """×‘×•×“×§ ×¡×˜×˜×•×¡ ×©×œ ×ª×”×œ×™×š."""
    if not proc: return '×œ× ×”×•×¤×¢×œ'
    return '×¨×¥' if proc.poll() is None else f'×”×¡×ª×™×™× (×§×•×“ {proc.returncode})'

def stop_process(key):
    """×¢×•×¦×¨ ×ª×”×œ×™×š ×œ×¤×™ ××¤×ª×— ×‘-session_state."""
    proc = st.session_state.get(key)
    if proc and proc.poll() is None:
        proc.terminate()
        st.session_state[key] = None
        st.toast(f"×”×ª×”×œ×™×š '{key}' × ×¢×¦×¨.")
        time.sleep(1)
        st.rerun()

st.set_page_config(
    page_title="×“×©×‘×•×¨×“ × ×™×”×•×œ - ×‘×•×˜ ××¡×—×¨ ××œ×’×•×¨×™×ª××™",
    layout="wide",
    initial_sidebar_state="expanded",
    page_icon="ğŸ“Š"
)
set_rtl_layout()

# --- × ×™×”×•×œ ×¡×™×¡××” ---
PASSWORD_FILE = Path("dashboard_password.txt")

def get_password_hash(pw):
    return hashlib.sha256(pw.encode()).hexdigest()

def check_dashboard_password(pw):
    if not PASSWORD_FILE.exists():
        default_pw = os.environ.get('DASHBOARD_PASSWORD', 'admin')
        with open(PASSWORD_FILE, 'w') as f:
            f.write(get_password_hash(default_pw))
    with open(PASSWORD_FILE, 'r') as f:
        saved_hash = f.read().strip()
    return get_password_hash(pw) == saved_hash

# --- ×ª×¤×¨×™×˜ ×¦×“ ×•××™××•×ª ---
st.sidebar.title("× ×™×•×•×˜")

if st.session_state.get('authenticated', False):  
    pass
elif cookies.get('authenticated_user'):
    st.session_state['authenticated'] = True
else:
    st.session_state['authenticated'] = False

if not st.session_state.authenticated:
    st.title("×›× ×™×¡×” ×œ××¢×¨×›×ª")
    pwd = st.text_input("×¡×™×¡××”:", type="password")
    if st.button("×”×ª×—×‘×¨"):
        if check_dashboard_password(pwd):
            st.session_state.authenticated = True
            cookies['authenticated_user'] = pwd
            cookies.save()
            st.rerun()
        else:
            st.error("×¡×™×¡××” ×©×’×•×™×”.")
    st.stop()

# --- ×ª×•×›×Ÿ ×”×“×©×‘×•×¨×“ (××•×¦×’ ×¨×§ ×œ××—×¨ ××™××•×ª) ---
page = st.sidebar.radio(
    "×‘×—×¨ ×¢××•×“:",
    ("×¡×§×™×¨×” ×›×œ×œ×™×ª", "× ×™×”×•×œ ×”××¢×¨×›×ª", "×œ×•×’×™×", "×ª×¦×•×¨×ª ××¢×¨×›×ª", "× ×™×ª×•×— ×ª×•×¦××•×ª"),
    key="nav_radio"
)
st.sidebar.markdown("---")
if st.sidebar.button("×”×ª× ×ª×§"):
    st.session_state.authenticated = False
    del cookies['authenticated_user']
    cookies.save()
    st.rerun()

# --- ×¢××•×“ ×¡×§×™×¨×” ×›×œ×œ×™×ª ---
if page == "×¡×§×™×¨×” ×›×œ×œ×™×ª":
    st.markdown("---")
    st.subheader(":rotating_light: ×¤×™×§×•×“ ×™×“× ×™")
    command_path = Path('agent/command.json')
    current_command = {}
    if command_path.exists():
        try:
            with open(command_path, encoding='utf-8') as f:
                content = f.read()
                current_command = json.loads(content) if content else {}
        except Exception:
            current_command = {}

    colmo1, colmo2, colmo3 = st.columns([2, 2, 2])
    with colmo1:
        if st.button("ğŸš¨ ×¡×’×•×¨ ××ª ×›×œ ×”×¤×•×–×™×¦×™×•×ª ××™×“ (×©×•×§)!", type="primary"):
            cmd = {"command": "CLOSE_ALL", "timestamp": datetime.now().isoformat()}
            with open(command_path, 'w', encoding='utf-8') as f:
                json.dump(cmd, f)
            st.warning("×¤×§×•×“×ª ×¡×’×™×¨×ª ×›×œ ×”×¤×•×–×™×¦×™×•×ª × ×©×œ×—×” ×œ×¡×•×›×Ÿ!", icon="âš ï¸")
    with colmo2:
        pause_state = current_command.get('pause_new_entries', False)
        pause_toggle = st.toggle("×”×©×”×” ×›× ×™×¡×” ×œ×¤×•×–×™×¦×™×•×ª ×—×“×©×•×ª", value=pause_state)
        if pause_toggle != pause_state:
            cmd = {"command": "PAUSE_NEW_ENTRIES", "pause_new_entries": pause_toggle, "timestamp": datetime.now().isoformat()}
            with open(command_path, 'w', encoding='utf-8') as f:
                json.dump(cmd, f)
            st.info(f"××¦×‘ ×”×©×”×™×™×ª ×›× ×™×¡×•×ª ×¢×•×“×›×Ÿ ×œ-{pause_toggle}")
    with colmo3:
        if st.button("ğŸ”„ ×”×¤×¢×œ ××—×“×© ××ª ×œ×•×’×™×§×ª ×”××¡×—×¨"):
            cmd = {"command": "RESTART_LOGIC", "timestamp": datetime.now().isoformat()}
            with open(command_path, 'w', encoding='utf-8') as f:
                json.dump(cmd, f)
            st.success("×¤×§×•×“×ª ×”×¤×¢×œ×” ××—×“×© × ×©×œ×—×” ×œ×¡×•×›×Ÿ.")

    st.title("ğŸ“Š ×¡×§×™×¨×” ×›×œ×œ×™×ª ×•××¦×‘ ×”××¢×¨×›×ª")
    
    # ×¡×˜×˜×•×¡ ××¢×¨×›×ª ×‘×–××Ÿ ×××ª
    st.subheader("ğŸ”„ ×¡×˜×˜×•×¡ ××¢×¨×›×ª ×‘×–××Ÿ ×××ª")
    
    # ×‘×“×™×§×ª ×¡×˜×˜×•×¡ ××™××•×Ÿ
    def check_training_status():
        try:
            # ×‘×“×™×§×” ×× ×§×™×™× ×ª×”×œ×™×š ××™××•×Ÿ ×¤×¢×™×œ
            import psutil
            for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
                if 'main_trainer.py' in ' '.join(proc.info['cmdline'] or []):
                    return "ğŸŸ¢ ×¤×¢×™×œ", f"PID: {proc.info['pid']}"
            return "ğŸ”´ ×œ× ×¤×¢×™×œ", "×œ× ×¨×¥ ×›×¨×’×¢"
        except:
            return "âšª ×œ× ×™×“×•×¢", "×œ× × ×™×ª×Ÿ ×œ×‘×“×•×§"
    
    # ×‘×“×™×§×ª ×¡×˜×˜×•×¡ backtester
    def check_backtester_status():
        try:
            import psutil
            for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
                if 'backtester.py' in ' '.join(proc.info['cmdline'] or []):
                    return "ğŸŸ¢ ×¤×¢×™×œ", f"PID: {proc.info['pid']}"
            return "ğŸ”´ ×œ× ×¤×¢×™×œ", "×œ× ×¨×¥ ×›×¨×’×¢"
        except:
            return "âšª ×œ× ×™×“×•×¢", "×œ× × ×™×ª×Ÿ ×œ×‘×“×•×§"
    
    # ×”×¦×’×ª ×¡×˜×˜×•×¡ ×‘××˜×¨×™×§×•×ª
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        api_proc = st.session_state.get('api_process')
        api_status = get_process_status(api_proc)
        st.metric("ğŸŒ ×©×¨×ª API", api_status)
    
    with col2:
        agent_proc = st.session_state.get('agent_process')
        agent_status = get_process_status(agent_proc)
        st.metric("ğŸ¤– ×¡×•×›×Ÿ ××¡×—×¨", agent_status)
    
    with col3:
        training_status, training_detail = check_training_status()
        st.metric("ğŸ§  ××™××•×Ÿ ××•×“×œ", training_status, training_detail)
    
    with col4:
        backtester_status, backtester_detail = check_backtester_status()
        st.metric("ğŸ“Š Backtester", backtester_status, backtester_detail)
    
    st.subheader("ğŸ›ï¸ ×‘×§×¨×ª ×ª×”×œ×™×›×™×")
    api_proc = st.session_state.get('api_process')
    agent_proc = st.session_state.get('agent_process')

    col1, col2 = st.columns(2)
    with col1:
        if api_proc and api_proc.poll() is None:
            if st.button("â¹ï¸ ×¢×¦×•×¨ ×©×¨×ª ×”-API"):
                stop_process('api_process')
        else:
            if st.button("â–¶ï¸ ×”×¤×¢×œ ×©×¨×ª ×”-API"):
                proc = subprocess.Popen([sys.executable, "model_api.py"])
                st.session_state['api_process'] = proc
                st.rerun()
    with col2:
        if agent_proc and agent_proc.poll() is None:
            if st.button("â¹ï¸ ×¢×¦×•×¨ ×¡×•×›×Ÿ ××¡×—×¨"):
                stop_process('agent_process')
        else:
            if st.button("â–¶ï¸ ×”×¤×¢×œ ×¡×•×›×Ÿ ××¡×—×¨"):
                proc = subprocess.Popen(["node", "agent/trading_agent.js"])
                st.session_state['agent_process'] = proc
                st.rerun()

    st.markdown("---")
    st.subheader(":chart_with_upwards_trend: ××¦×‘ ×¤×•×–×™×¦×™×” ×—×™")
    db_path = 'agent/state.db'
    trade_state = {}
    try:
        conn = sqlite3.connect(f"file:{db_path}?mode=ro", uri=True)
        cur = conn.cursor()
        row = cur.execute("SELECT value FROM state WHERE key = ?", ('trade_state',)).fetchone()
        trade_state = json.loads(row[0]) if row and row[0] else {}
        conn.close()
    except Exception as e:
        st.error(f"×©×’×™××” ×‘×’×™×©×” ×œ-agent/state.db: {e}")

    position = trade_state.get('position')
    size = trade_state.get('size')
    entry = trade_state.get('entryPrice')
    stop_loss = trade_state.get('stopLoss')
    take_profit = trade_state.get('takeProfit')
    
    try:
        config = load_system_config()
        symbol = config.get('contract', {}).get('symbol', 'SPY')
    except Exception:
        symbol = 'SPY'

    st.info(f"× ×›×¡: {symbol}")
    if not position:
        st.write(":blue_circle: ××™×Ÿ ×¤×•×–×™×¦×™×” ×¤×¢×™×œ×”.")
    else:
        st.write(f"**×¤×•×–×™×¦×™×” × ×•×›×—×™×ª:** {'×œ×•× ×’' if position == 'long' else '×©×•×¨×˜' if position == 'short' else position}")
        st.write(f"**×’×•×“×œ:** {size if size is not None else '-'} ×× ×™×•×ª")
        st.write(f"**××—×™×¨ ×›× ×™×¡×”:** ${entry if entry is not None else '-'}")
        st.write(f"**×¢×¦×™×¨×ª ×”×¤×¡×“ (SL):** ${stop_loss if stop_loss is not None else '-'}")
        st.write(f"**×œ×§×™×—×ª ×¨×•×•×— (TP):** ${take_profit if take_profit is not None else '-'}")

    colr1, colr2 = st.columns([1, 1])
    with colr1:
        if st.button("×¨×¢× ×Ÿ ××¦×‘ ×¤×•×–×™×¦×™×”"):
            st.rerun()
    with colr2:
        refresh = st.checkbox("×¨×¢× ×•×Ÿ ××•×˜×•××˜×™ ×›×œ 5 ×©× ×™×•×ª", value=False)
        if refresh:
            time.sleep(5)
            st.rerun()

    st.markdown("---")
    st.subheader("×‘×“×™×§×ª ×–××™× ×•×ª ×”-API")
    try:
        resp = requests.get("http://localhost:5000/status", timeout=3)
        if resp.status_code == 200 and resp.json().get('model_loaded'):
            st.success("×©×¨×ª ×”-API ×¤×¢×™×œ ×•×”××•×“×œ ×˜×¢×•×Ÿ ×‘×”×¦×œ×—×”.", icon="âœ…")
            st.json(resp.json())
        else:
            st.warning("×©×¨×ª ×”-API ×–××™×Ÿ ××š ×”××•×“×œ ×œ× ×˜×¢×•×Ÿ ××• ×©×™×©× ×” ×‘×¢×™×” ××—×¨×ª.", icon="âš ï¸")
    except requests.exceptions.ConnectionError:
        st.error("×©×¨×ª ×”-API ×œ× ×–××™×Ÿ. ×•×“× ×©×”×¤×¢×œ×ª ××ª ×©×¨×ª ×”-API.", icon="âŒ")
    except Exception as e:
        st.error(f"×©×’×™××” ×‘×‘×“×™×§×ª ×©×¨×ª ×”-API: {e}")

# --- ×¢××•×“ × ×™×”×•×œ ×”××¢×¨×›×ª ---
elif page == "× ×™×”×•×œ ×”××¢×¨×›×ª":
    st.markdown("---")
    st.subheader(":bar_chart: ×‘×¨×™××•×ª × ×ª×•× ×™× (Data Health)")
    data_files = [
        ("SPY_ibkr.csv", "data/raw/SPY_ibkr.csv"),
        ("VIX_ibkr.csv", "data/raw/VIX_ibkr.csv"),
        ("SPY_processed.csv", "data/processed/SPY_processed.csv")
    ]
    table = []
    for label, path in data_files:
        file_info = {"×§×•×‘×¥": label, "×ª××¨×™×š ×©×™× ×•×™": "-", "×’×•×“×œ (MB)": "-", "×©×•×¨×•×ª": "-"}
        if os.path.exists(path):
            stat = os.stat(path)
            file_info["×ª××¨×™×š ×©×™× ×•×™"] = datetime.fromtimestamp(stat.st_mtime).strftime("%Y-%m-%d %H:%M")
            file_info["×’×•×“×œ (MB)"] = f"{stat.st_size/1024/1024:.2f}"
            try:
                nrows = sum(1 for _ in open(path, encoding='utf-8', errors='ignore')) - 1
                file_info["×©×•×¨×•×ª"] = str(nrows)
            except Exception:
                file_info["×©×•×¨×•×ª"] = "?"
        table.append(file_info)
    st.table(table)

    if st.button("ğŸ§¹ ××¤×¡ ×•××¡×•×£ ×”×›×œ ××—×“×©", type="primary"):
        for _, path in data_files:
            if os.path.exists(path):
                try:
                    os.remove(path)
                except Exception:
                    pass
        st.info("×”×§×‘×¦×™× × ××—×§×•. ××¨×™×¥ pipeline ××œ×...")
        run_and_stream_process([sys.executable, "run_all.py"], "××¨×™×¥ pipeline ××œ× ×œ××™×¡×•×£ × ×ª×•× ×™× ×•×¢×™×‘×•×“...")
    
    st.title("âš™ï¸ × ×™×”×•×œ ×•×ª×¤×¢×•×œ ×”××¢×¨×›×ª")
    st.subheader("×”×¨×¦×ª ×¦×™× ×•×¨ ×”× ×ª×•× ×™× ×•×”××™××•×Ÿ ×”××œ×")
    st.info("×ª×”×œ×™×š ×–×” ××¨×™×¥ ××™×¡×•×£ × ×ª×•× ×™×, ×¢×™×‘×•×“ ××§×“×™× ×•××™××•×Ÿ ××•×“×œ ×—×“×© ×‘×¨×¦×£.")
    if st.button("ğŸš€ ×”×¨×¥ ××ª ×›×œ ×”×ª×”×œ×™×š (Run All)"):
        run_and_stream_process([sys.executable, "run_all.py"], "××¨×™×¥ ××ª ×›×œ ×¦×™× ×•×¨ ×”× ×ª×•× ×™× ×•×”××™××•×Ÿ...")

    st.markdown("---")
    st.subheader("×”×¨×¦×ª ×ª×”×œ×™×›×™× ×‘×•×“×“×™×")
    col1, col2, col3 = st.columns(3)
    with col1:
        if st.button("1. ××™×¡×•×£ × ×ª×•× ×™×"):
            run_and_stream_process([sys.executable, "src/data_collector.py"], "××•×¡×£ × ×ª×•× ×™×...")
    with col2:
        if st.button("2. ×¢×™×‘×•×“ × ×ª×•× ×™×"):
            run_and_stream_process([sys.executable, "run_preprocessing.py"], "××¢×‘×“ × ×ª×•× ×™×...")
    with col3:
        if st.button("3. ××™××•×Ÿ ××•×“×œ"):
            run_and_stream_process([sys.executable, "main_trainer.py"], "××¨×™×¥ ××™××•×Ÿ ×•××•×¤×˜×™××™×–×¦×™×”...")

# --- ×¢××•×“ ×œ×•×’×™× ---
elif page == "×œ×•×’×™×":
    st.title("ğŸ“œ ×¦×¤×™×™×” ×‘×œ×•×’×™× ×•×“×•×—×•×ª ××¢×¨×›×ª")
    log_dirs = [Path("logs"), Path("agent"), Path("db")]
    all_files = []
    for log_dir in log_dirs:
        if log_dir.exists():
            all_files.extend(log_dir.glob("**/*"))

    all_files = [f for f in all_files if f.is_file()]

    log_desc = {
        'main_trainer_output.log': '×œ×•×’ ××™××•×Ÿ ××•×“×œ (main_trainer)',
        'backtester_output.log': '×œ×•×’ ×‘×“×™×§×•×ª Backtest',
        'trading_log.txt': '×™×•××Ÿ ×¤×§×•×“×•×ª ××¡×—×¨',
        'state.db': '××¡×“ × ×ª×•× ×™× ×©×œ ××¦×‘ ×”×¡×•×›×Ÿ',
        'test_order.js': '×§×•×“ ×‘×“×™×§×•×ª ×œ×¡×•×›×Ÿ',
        'state_manager.js': '× ×™×”×•×œ ××¦×‘ ×¡×•×›×Ÿ',
        'trading_agent.js': '×§×•×“ ×¡×•×›×Ÿ ××¡×—×¨',
    }

    def get_log_label(p: Path):
        desc = log_desc.get(p.name, "")
        return f"{p.name} â€” {desc}" if desc else str(p)

    if all_files:
        all_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
        file_labels = [get_log_label(f) for f in all_files]
        selected_idx = st.selectbox(
            "×‘×—×¨ ×§×•×‘×¥ ×œ×•×’ ××• ×“×•×— ×œ×”×¦×’×” (××¡×•×“×¨ ×œ×¤×™ ×¢×“×›×•×Ÿ ××—×¨×•×Ÿ):",
            range(len(all_files)),
            format_func=lambda i: file_labels[i]
        )
        selected_file_path = all_files[selected_idx]
        if selected_file_path:
            p = Path(selected_file_path)
            st.download_button(f"ğŸ“¥ ×”×•×¨×“ ××ª {p.name}", data=p.read_bytes(), file_name=p.name)

            if p.suffix.lower() not in ['.db', '.pkl', '.json', '.zip', '.egg', '.pyc']:
                try:
                    with open(p, 'r', encoding='utf-8', errors='ignore') as f:
                        lines = f.readlines()
                    last_lines = lines[-200:] if len(lines) > 200 else lines
                    st.text_area(f"×ª×•×›×Ÿ {get_log_label(p)} ({len(last_lines)} ×©×•×¨×•×ª ××—×¨×•× ×•×ª)", "".join(last_lines), height=400)
                except Exception as e:
                    st.error(f"×œ× × ×™×ª×Ÿ ×”×™×” ×œ×§×¨×•× ××ª ×”×§×•×‘×¥: {e}")
            else:
                st.info(f"×œ× × ×™×ª×Ÿ ×œ×”×¦×™×’ ×ª×¦×•×’×” ××§×“×™××” ×œ×§×‘×¦×™× ××¡×•×’ '{p.suffix}'.")
    else:
        st.warning("×œ× × ××¦××• ×§×‘×¦×™ ×œ×•×’ ××• ×“×•×—×•×ª.")

# --- ×¢××•×“ ×ª×¦×•×¨×ª ××¢×¨×›×ª ---
elif page == "×ª×¦×•×¨×ª ××¢×¨×›×ª":
    try:
        config_data = load_system_config()
    except Exception as e:
        st.error(f"×©×’×™××” ×§×¨×™×˜×™×ª ×‘×˜×¢×™× ×ª system_config.json: {e}")
        st.stop()
    
    # ×”×§×˜× ×ª ×”×“×£ ×‘×¢××•×“×•×ª
    col1, col2, col3 = st.columns([1, 4, 1])
    
    with col2:  # ×”×©×“×•×ª ×™×•×¤×™×¢×• ×‘×¢××•×“×” ×”×××¦×¢×™×ª
        st.title("ğŸ“ ×¢×¨×™×›×ª ×ª×¦×•×¨×ª ×”××¢×¨×›×ª")
        
        with st.form(key='config_form'):
            edited_config = json.loads(json.dumps(config_data))

            with st.expander("×¤×¨××˜×¨×™ ××™××•×Ÿ (Training)", expanded=False):
                # ×©×™××•×© ×‘×¢××•×“×•×ª ×¤× ×™××™×•×ª ×œ×§×™×¦×•×¨
                c1, c2 = st.columns(2)
                with c1:
                    edited_config['training_params']['n_trials'] = st.number_input("××¡×¤×¨ × ×™×¡×™×•× ×•×ª Optuna", min_value=1, value=edited_config['training_params'].get('n_trials', 100))
                    edited_config['training_params']['cv_splits'] = st.number_input("××¡×¤×¨ ×§×¤×œ×™× (CV)", min_value=2, value=edited_config['training_params'].get('cv_splits', 5))
                    test_size_percent = st.number_input("××—×•×– ×‘×“×™×§×”", min_value=10, max_value=50, value=int(edited_config['training_params'].get('test_size_split', 20)), step=1)
                    edited_config['training_params']['test_size_split'] = test_size_percent
                
                with c2:
                    edited_config['training_params']['n_startup_trials'] = st.number_input("× ×™×¡×™×•× ×•×ª ××§×¨××™×™×", min_value=0, value=edited_config['training_params'].get('n_startup_trials', 10))
                    edited_config['training_params']['years_of_data'] = st.number_input("×©× ×•×ª × ×ª×•× ×™×", min_value=1, max_value=30, value=edited_config['training_params'].get('years_of_data', 15))
                    
                    optuna_target_options = {
                        'multi_objective': '×¨×‘-×™×¢×“×™',
                        'total_return': '×ª×©×•××”',
                        'sharpe_ratio': '×©××¨×¤'
                    }
                    optuna_target_default = edited_config['training_params'].get('optuna_target_metric', 'multi_objective')
                    if optuna_target_default not in optuna_target_options:
                        optuna_target_default = list(optuna_target_options.keys())[0]
                    optuna_target_index = list(optuna_target_options.keys()).index(optuna_target_default)
                    optuna_target = st.selectbox("×™×¢×“ ××•×¤×˜×™××™×–×¦×™×”", options=list(optuna_target_options.keys()), format_func=lambda k: optuna_target_options[k], index=optuna_target_index)
                    edited_config['training_params']['optuna_target_metric'] = optuna_target

            with st.expander("×”×’×“×¨×ª ×’×‘×•×œ×•×ª ×œ×¤×¨××˜×¨×™ ××•×¤×˜×™××™×–×¦×™×” (Optuna)", expanded=False):
                optuna_limits = edited_config.get('optuna_param_limits', {})
                
                param_labels = {
                    'horizon': '××•×¤×§ (×™××™×)', 'threshold': '×¡×£ (%)',
                    'top_n_features': '×¤×™×¦×³×¨×™×', 
                    'stop_loss_pct': '×”×¤×¡×“ (%)',
                    'take_profit_pct': '×¨×•×•×— (%)',
                    'risk_per_trade': '×¡×™×›×•×Ÿ (%)',
                    'learning_rate': '×œ××™×“×”', 'n_estimators': '×¢×¦×™×', 'max_depth': '×¢×•××§'
                }
                
                for param, lims in optuna_limits.items():
                    if param not in param_labels: continue

                    label = param_labels[param]
                    st.markdown(f"**{label}**")
                    col1, col2, col3 = st.columns(3)

                    is_dynamic = lims.get('optimize', True)
                    min_val = lims.get('min', 0)
                    max_val = lims.get('max', 1)
                    fixed_val = lims.get('fixed_value', min_val)
                    
                    with col1:
                        user_min = st.number_input(
                            "××™× ×™××•×", 
                            key=f"min_{param}", 
                            value=float(min_val), 
                            format="%.4f"
                        )
                    with col2:
                        user_max = st.number_input(
                            "××§×¡×™××•×", 
                            key=f"max_{param}", 
                            value=float(max_val), 
                            format="%.4f"
                        )
                    with col3:
                        user_fixed = st.number_input(
                            "×¢×¨×š ×§×‘×•×¢", 
                            key=f"fixed_{param}", 
                            value=float(fixed_val), 
                            format="%.4f"
                        )
                    
                    new_dynamic_state = st.checkbox(
                        "××•×¤×˜×™××™×–×¦×™×” ×¤×¢×™×œ×”", 
                        value=is_dynamic, 
                        key=f"opt_{param}"
                    )

                    edited_config['optuna_param_limits'][param]['optimize'] = new_dynamic_state
                    edited_config['optuna_param_limits'][param]['min'] = user_min
                    edited_config['optuna_param_limits'][param]['max'] = user_max
                    edited_config['optuna_param_limits'][param]['fixed_value'] = user_fixed
                    st.divider()

            with st.expander("×¤×¨××˜×¨×™ Backtest", expanded=False):
                edited_config['backtest_params']['initial_balance'] = st.number_input("×™×ª×¨×ª ×”×ª×—×œ×” ($)", min_value=1000, value=edited_config['backtest_params'].get('initial_balance', 100000))
                edited_config['backtest_params']['commission'] = st.number_input("×¢××œ×” (0.001 = 0.1%)", min_value=0.0, max_value=0.01, value=edited_config['backtest_params'].get('commission', 0.001), step=0.0001, format="%.4f")
                edited_config['backtest_params']['slippage'] = st.number_input("×”×—×œ×§×” (0.0005 = 0.05%)", min_value=0.0, max_value=0.01, value=edited_config['backtest_params'].get('slippage', 0.0005), step=0.0001, format="%.4f")
                edited_config['backtest_params']['min_history_days'] = st.number_input("×™××™ ×”×™×¡×˜×•×¨×™×” ××™× ×™××œ×™×™×", min_value=30, max_value=365, value=edited_config['backtest_params'].get('min_history_days', 100), help="××¡×¤×¨ ×™××™ ××¡×—×¨ ××™× ×™××œ×™ ×œ×¤× ×™ ×ª×—×™×œ×ª ×”×‘×§×˜×¡×˜")
                
                # ×”×•×¡×¤×ª ×¤×¨××˜×¨×™ ×¡×™×›×•×Ÿ
                if 'risk_params' not in edited_config:
                    edited_config['risk_params'] = {}
                edited_config['risk_params']['position_size_pct'] = st.number_input("××—×•×– ×’×•×“×œ ×¤×•×–×™×¦×™×” (0.1 = 10%)", min_value=0.01, max_value=1.0, value=edited_config['risk_params'].get('position_size_pct', 0.1), step=0.01, format="%.2f", help="××—×•×– ××§×¡×™××œ×™ ××”×ª×™×§ ×œ×¤×•×–×™×¦×™×” ××—×ª")

            with st.expander("×¤×¨×˜×™ ×—×•×–×” ×•× ×›×¡ (Contract)", expanded=False):
                if 'contract' not in edited_config:
                    edited_config['contract'] = {}
                
                c1, c2 = st.columns(2)
                with c1:
                    edited_config['contract']['symbol'] = st.text_input("×¡×™××‘×•×œ", value=edited_config['contract'].get('symbol', 'SPY'))
                    edited_config['contract']['secType'] = st.selectbox("×¡×•×’ × ×™×™×¨ ×¢×¨×š", options=['STK', 'OPT', 'FUT', 'CASH', 'CFD'], index=0 if edited_config['contract'].get('secType', 'STK') == 'STK' else 0, help="STK = ×× ×™×•×ª, OPT = ××•×¤×¦×™×•×ª, FUT = ×¢×ª×™×“×™×™×")
                    edited_config['contract']['exchange'] = st.text_input("×‘×•×¨×¡×”", value=edited_config['contract'].get('exchange', 'SMART'), help="SMART = × ×™×ª×•×‘ ×—×›×, NASDAQ, NYSE, ×•×›×•'")
                with c2:
                    edited_config['contract']['currency'] = st.selectbox("××˜×‘×¢", options=['USD', 'EUR', 'GBP', 'JPY', 'CAD', 'AUD'], index=0 if edited_config['contract'].get('currency', 'USD') == 'USD' else 0)
                    edited_config['contract']['primaryExch'] = st.text_input("×‘×•×¨×¡×” ×¨××©×™×ª", value=edited_config['contract'].get('primaryExch', 'ARCA'), help="ARCA, NASDAQ, NYSE, ×•×›×•'")
                    
                # ×”×¢×¨×” ×—×©×•×‘×” ×¢×œ ×¤×¨××˜×¨×™ ×¡×™×›×•×Ÿ
                st.info("ğŸ’¡ **×¤×¨××˜×¨×™ ×¡×™×›×•×Ÿ** (×¢×¦×™×¨×ª ×”×¤×¡×“, ×œ×§×™×—×ª ×¨×•×•×—, ×¡×™×›×•×Ÿ ×œ×¢×¡×§×”) × ××¦××™× ×‘×˜××‘ '×¤×¨××˜×¨×™ ××•×¤×˜×™××™×–×¦×™×”'. ×©× ×ª×•×›×œ ×œ×”×’×“×™×¨ ××•×ª× ×›×§×‘×•×¢×™× ××• ×œ××¤×˜××™×–×¦×™×”.")

            with st.expander("×”×’×“×¨×•×ª ×—×™×‘×•×¨×™× (API & IBKR)", expanded=False):
                c1, c2 = st.columns(2)
                with c1:
                    edited_config['api_settings']['host'] = st.text_input("×›×ª×•×‘×ª API", value=edited_config['api_settings'].get('host', '0.0.0.0'), help="×›×ª×•×‘×ª ×”×©×¨×ª ×œAPI")
                    edited_config['api_settings']['port'] = st.number_input("×¤×•×¨×˜ API", min_value=1024, max_value=65535, value=edited_config['api_settings'].get('port', 5000))
                    edited_config['ibkr_settings']['host'] = st.text_input("×›×ª×•×‘×ª IBKR", value=edited_config['ibkr_settings'].get('host', '127.0.0.1'), help="×›×ª×•×‘×ª ×©×¨×ª Interactive Brokers")
                    edited_config['ibkr_settings']['port'] = st.number_input("×¤×•×¨×˜ IBKR", min_value=1024, max_value=65535, value=edited_config['ibkr_settings'].get('port', 4001))
                with c2:
                    edited_config['ibkr_settings']['clientId'] = st.number_input("IBKR Client ID", min_value=1, value=edited_config['ibkr_settings'].get('clientId', 101))
                    edited_config['ibkr_settings']['history_window'] = st.text_input("×—×œ×•×Ÿ ×–××Ÿ × ×ª×•× ×™×", value=edited_config['ibkr_settings'].get('history_window', '90 D'), help="×›××” ×–××Ÿ ××—×•×¨×” ×œ×˜×¢×•×Ÿ × ×ª×•× ×™× (×œ××©×œ: '90 D', '1 Y')")
                    
                    # ×”×’×“×¨×•×ª ××¦×‘ ×‘×“×™×§×”
                    if 'agent_settings' not in edited_config:
                        edited_config['agent_settings'] = {}
                    edited_config['agent_settings']['TEST_MODE_ENABLED'] = st.checkbox("××¦×‘ ×‘×“×™×§×”", value=edited_config['agent_settings'].get('TEST_MODE_ENABLED', True), help="××¦×‘ ×‘×“×™×§×” - ×œ× ××‘×¦×¢ ×¢×¡×§××•×ª ×××™×ª×™×•×ª")
                    
                    if edited_config['agent_settings']['TEST_MODE_ENABLED']:
                        edited_config['agent_settings']['TEST_BUY_QUANTITY'] = st.number_input("×›××•×ª ×‘×“×™×§×”", min_value=1, value=edited_config['agent_settings'].get('TEST_BUY_QUANTITY', 1), help="×›××•×ª ×× ×™×•×ª ×‘××¦×‘ ×‘×“×™×§×”")
                        edited_config['agent_settings']['TEST_BUY_PRICE_FACTOR'] = st.number_input("×¤×§×˜×•×¨ ××—×™×¨ ×‘×“×™×§×”", min_value=0.5, max_value=1.5, value=edited_config['agent_settings'].get('TEST_BUY_PRICE_FACTOR', 0.95), step=0.01, format="%.2f", help="×¤×§×˜×•×¨ ×”××—×™×¨ ×‘××¦×‘ ×‘×“×™×§×” (0.95 = 95% ××”××—×™×¨)")

            submitted = st.form_submit_button("ğŸ’¾ ×©××•×¨ ×©×™× ×•×™×™×", use_container_width=True)
            if submitted:
                try:
                    save_system_config(edited_config)
                    show_alert("×”×”×’×“×¨×•×ª × ×©××¨×• ×‘×”×¦×œ×—×”!", type_='success')
                    st.rerun()
                except Exception as e:
                    show_alert(f"×©×’×™××” ×‘×©××™×¨×ª ×”×”×’×“×¨×•×ª: {e}", type_='error')

# --- ×¢××•×“ × ×™×ª×•×— ×ª×•×¦××•×ª ---
elif page == "× ×™×ª×•×— ×ª×•×¦××•×ª":
    st.title("ğŸ“ˆ × ×™×ª×•×— ×ª×•×¦××•×ª")
    
    tab1, tab2, tab3, tab4 = st.tabs(["×ª×•×¦××•×ª Backtest", "× ×™×ª×•×— ××•×¤×˜×™××™×–×¦×™×” (Optuna)", "×¡×™×›×•× ××™××•× ×™× ×§×•×“××™×", "×§×™×“×•× ××•×“×œ×™× (Staging)"])

    with tab1:
        st.header("× ×™×ª×•×— Backtest")
        results_dir = Path("reports/backtest_results")
        
        summary_files = sorted(results_dir.glob("summary_*.json"), key=os.path.getmtime, reverse=True)
        summary_options = {f.name: f for f in summary_files}
        
        selected_summary_name = st.selectbox("×‘×—×¨ ×¨×™×¦×ª ×‘×§×˜×¡×˜ ×œ×”×¦×’×”:", list(summary_options.keys()))

        if selected_summary_name:
            selected_summary_path = summary_options[selected_summary_name]
            suffix = selected_summary_name.replace("summary_", "").replace(".json", "")
            
            equity_path = results_dir / f"equity_curve_{suffix}.csv"
            trades_path = results_dir / f"trades_{suffix}.csv"

            with open(selected_summary_path, encoding="utf-8") as f:
                summary = json.load(f)
            
            st.subheader(f"××“×“×™× ××¨×›×–×™×™× ×¢×‘×•×¨: {suffix}")
            cols = st.columns(4)
            cols[0].metric("×ª×©×•××” ×›×•×œ×œ×ª", f"{summary.get('total_return', 0)*100:.2f}%")
            cols[1].metric("×™×—×¡ ×©××¨×¤", f"{summary.get('sharpe_ratio', 0):.2f}")
            cols[2].metric("×™×¨×™×“×ª ×¢×¨×š ××™×¨×‘×™×ª", f"{summary.get('max_drawdown', 0)*100:.2f}%")
            cols[3].metric("××—×•×– ×”×¦×œ×—×•×ª", f"{summary.get('win_rate', 0)*100:.2f}%")

            if equity_path.exists():
                try:
                    equity_df = pd.read_csv(equity_path, index_col=0, parse_dates=True)
                    fig_equity = px.line(equity_df, y=['equity', 'benchmark_equity'], title=f'Equity Curve vs. Benchmark ({suffix})', labels={'value': 'Equity ($)', 'date': 'Date', 'variable': 'Strategy'})
                    fig_equity.update_layout(legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1))
                    st.plotly_chart(fig_equity, use_container_width=True)
                except Exception as e:
                    st.error(f"×©×’×™××” ×‘×’×¨×£ ×”-Equity: {e}")
            else:
                st.warning(f"×§×•×‘×¥ ×¢×§×•××ª ×”×•×Ÿ ×œ× × ××¦× ×¢×‘×•×¨ {suffix}")
                
            if trades_path.exists():
                st.subheader(f"× ×™×ª×•×— ×¢×¡×§××•×ª ({suffix})")
                try:
                    trades_df = pd.read_csv(trades_path)
                    st.dataframe(trades_df.tail())
                except Exception as e:
                    st.error(f"×©×’×™××” ×‘× ×™×ª×•×— ×§×•×‘×¥ ×”×¢×¡×§××•×ª: {e}")
            else:
                st.warning(f"×§×•×‘×¥ ×¢×¡×§××•×ª ×œ× × ××¦× ×¢×‘×•×¨ {suffix}")
        else:
            st.info("×œ× × ××¦××• ×§×‘×¦×™ ×ª×•×¦××•×ª ×‘×§×˜×¡×˜. ×™×© ×œ×”×¨×™×¥ ×‘×§×˜×¡×˜ ×ª×—×™×œ×”.")

    with tab2:
        st.header("× ×™×ª×•×— ××•×¤×˜×™××™×–×¦×™×” (Optuna)")
        st.info("××¦×™×’ ×ª×•×¦××•×ª ××§×•×‘×¥ ××¡×“ ×”× ×ª×•× ×™× ×©×œ Optuna, ×”××™×•×¦×¨ ××•×˜×•××˜×™×ª ×‘×¢×ª ×”×¨×¦×ª ×”××™××•×Ÿ.")
        db_path = Path("db/spy_strategy_optimization.db")
        if db_path.exists():
            optuna_proc = st.session_state.get('optuna_dashboard_proc')
            if optuna_proc and optuna_proc.poll() is None:
                if st.button("â¹ï¸ ×¢×¦×•×¨ ××ª ×“×©×‘×•×¨×“ Optuna"):
                    stop_process('optuna_dashboard_proc')
            else:
                if st.button("â–¶ï¸ ×”×¤×¢×œ ××ª ×“×©×‘×•×¨×“ Optuna ×”×—×™"):
                    try:
                        cmd = ["optuna-dashboard", f"sqlite:///{db_path.resolve()}"]
                        proc = subprocess.Popen(cmd)
                        st.session_state['optuna_dashboard_proc'] = proc
                        st.success("×“×©×‘×•×¨×“ Optuna ×”×•×¤×¢×œ! ×¤×ª×— ××•×ª×• ×‘×›×ª×•×‘×ª http://127.0.0.1:8080 ×‘×“×¤×“×¤×Ÿ.")
                    except Exception as e:
                        st.error(f"×©×’×™××” ×‘×”×¤×¢×œ×ª ×“×©×‘×•×¨×“ Optuna: {e}")

            st.markdown("---")
            st.subheader("×”×¦×’×ª ×’×¨×¤×™× ×¡×˜×˜×™×™× ××”××™××•×Ÿ ×”××—×¨×•×Ÿ")
            try:
                config = load_system_config()
                selected_objective = config['training_params'].get('optuna_target_metric', 'multi_objective')
                
                # ××¦×™××ª ×”-study ×”×¢×“×›× ×™ ×‘×™×•×ª×¨
                conn = sqlite3.connect(f"file:{db_path.resolve()}?mode=ro", uri=True)
                studies_df = pd.read_sql_query("SELECT study_name FROM studies ORDER BY study_id DESC", conn)
                conn.close()
                
                if not studies_df.empty:
                    study_name = studies_df['study_name'].iloc[0]
                    st.info(f"×˜×•×¢×Ÿ × ×ª×•× ×™× ×¢×‘×•×¨ ×”-study ×”×¢×“×›× ×™ ×‘×™×•×ª×¨: `{study_name}`")
                    study = optuna.load_study(study_name=study_name, storage=f"sqlite:///{db_path.resolve()}")
                    
                    try:
                        st.plotly_chart(optuna.visualization.plot_optimization_history(study), use_container_width=True)
                    except Exception as e:
                        st.error(f"×©×’×™××” ×‘×”×¦×’×ª ×’×¨×£ ×”×™×¡×˜×•×¨×™×™×ª ××•×¤×˜×™××™×–×¦×™×”: {e}")
                    
                    try:
                        st.plotly_chart(optuna.visualization.plot_parallel_coordinate(study), use_container_width=True)
                    except Exception as e:
                        st.error(f"×©×’×™××” ×‘×”×¦×’×ª ×’×¨×£ ×§×•××•×¨×“×™× ×˜×•×ª ××§×‘×™×œ×•×ª: {e}")
                    
                    try:
                        st.plotly_chart(optuna.visualization.plot_param_importances(study), use_container_width=True)
                    except Exception as e:
                        st.error(f"×©×’×™××” ×‘×”×¦×’×ª ×’×¨×£ ×—×©×™×‘×•×ª ×¤×¨××˜×¨×™×: {e}")
                else:
                    st.warning("×œ× × ××¦××• ××—×§×¨×™ Optuna (studies) ×‘××¡×“ ×”× ×ª×•× ×™×.")
            except ImportError:
                st.error("×”×—×‘×™×œ×•×ª 'optuna' ×•-'plotly' ××™× ×Ÿ ××•×ª×§× ×•×ª ×‘×¡×‘×™×‘×” ×–×•.")
            except Exception as e:
                st.error(f"×©×’×™××” ×‘×˜×¢×™× ×ª × ×ª×•× ×™ ×”-Study ×©×œ Optuna: {e}")
        else:
            st.warning("×§×•×‘×¥ ××¡×“ ×”× ×ª×•× ×™× ×©×œ Optuna ×œ× × ××¦×. ×™×© ×œ×”×¨×™×¥ ××™××•×Ÿ ×ª×—×™×œ×”.")

    with tab3:
        st.header("×¡×™×›×•× ××™××•× ×™× ×§×•×“××™× (training_summary.json)")
        models_dir = Path('models')
        results_dir = Path('reports/backtest_results')
        df_for_iteration = load_training_summaries()
        
        # ×›×¤×ª×•×¨ ×œ××—×™×§×ª ×›×œ ×”×¨×™×¦×•×ª
        if not df_for_iteration.empty:
            st.markdown("---")
            delete_col1, delete_col2 = st.columns([3, 1])
            
            with delete_col2:
                if st.button("ğŸ—‘ï¸ ××—×§ ×›×œ ×”×¨×™×¦×•×ª", help="××—×§ ××ª ×›×œ ×§×‘×¦×™ ×”××™××•× ×™× ×•×”×ª×•×¦××•×ª", type="secondary"):
                    try:
                        deleted_files = 0
                        deleted_dirs = 0
                        
                        # ××—×™×§×ª ×ª×™×§×™×™×ª ×”××•×“×œ×™×
                        if models_dir.exists():
                            import shutil
                            shutil.rmtree(models_dir)
                            deleted_dirs += 1
                        
                        # ××—×™×§×ª ×ª×™×§×™×™×ª ×ª×•×¦××•×ª ×”×‘×§×˜×¡×˜
                        if results_dir.exists():
                            import shutil
                            shutil.rmtree(results_dir)
                            deleted_dirs += 1
                        
                        # ××—×™×§×ª ×§×•×‘×¥ ××¡×“ ×”× ×ª×•× ×™× ×©×œ Optuna
                        db_path = Path('spy_strategy_optimization.db')
                        if db_path.exists():
                            db_path.unlink()
                            deleted_files += 1
                        
                        # ××—×™×§×ª ×§×‘×¦×™ ×œ×•×’×™×
                        log_files = ['main_trainer_output.log', 'backtester_output.log', 'all_features_computed.log']
                        for log_file in log_files:
                            log_path = Path(log_file)
                            if log_path.exists():
                                log_path.unlink()
                                deleted_files += 1
                        
                        st.success(f"âœ… × ××—×§×• {deleted_files} ×§×‘×¦×™× ×•-{deleted_dirs} ×ª×™×§×™×•×ª")
                        st.rerun()
                        
                    except Exception as e:
                        st.error(f"×©×’×™××” ×‘××—×™×§×ª ×”×§×‘×¦×™×: {e}")
                        st.code(traceback.format_exc())
            
            st.markdown("---")
        
        param_he_map = {
            'timestamp': '×ª××¨×™×š', 'optuna_scores': '×¦×™×•× ×™ Optuna',
            'test_accuracy': '×“×™×•×§ ×›×œ×œ×™', 
            'recall_0': '×¨×™×›×•×œ (0-Hold)', 'precision_0': '×“×™×•×§ (0-Hold)', 'f1_0': 'F1 (0-Hold)', 'support_0': '×“×’×™××•×ª (0-Hold)',
            'recall_1': '×¨×™×›×•×œ (1-Buy)', 'precision_1': '×“×™×•×§ (1-Buy)', 'f1_1': 'F1 (1-Buy)', 'support_1': '×“×’×™××•×ª (1-Buy)',
            'horizon': '××•×¤×§ (×™××™×)', 'threshold': '×¡×£ ×”×—×œ×˜×” (%)', 'top_n_features': '××¡×¤×¨ ×¤×™×¦×³×¨×™×',
            'stop_loss_pct': '×¢×¦×™×¨×ª ×”×¤×¡×“ (%)',       # ×—×“×©
            'take_profit_pct': '×œ×§×™×—×ª ×¨×•×•×— (%)',     # ×—×“×©
            'risk_per_trade': '×¡×™×›×•×Ÿ ×œ×¢×¡×§×” (%)', 'learning_rate': '×§×¦×‘ ×œ××™×“×”',
            'n_estimators': '××¡×¤×¨ ×¢×¦×™×', 'max_depth': '×¢×•××§ ××™×¨×‘×™',
        }
        if df_for_iteration.empty:
            st.info("×œ× × ××¦××• ×¡×™×›×•××™ ××™××•×Ÿ ×‘××¨×›×™×•×Ÿ ××• ×‘×ª×™×§×™×” ×”×¨××©×™×ª.")
        else:
            st.markdown("#### ×œ×—×¥ ×¢×œ ×¨×™×¦×ª ××™××•×Ÿ ×›×“×™ ×œ×¨××•×ª ×¤×¨×˜×™× ××œ××™× ×•×œ×”×¨×™×¥ ×‘×§×˜×¡×˜:")
            for index, row in df_for_iteration.iterrows():
                try:
                    optuna_target_options = {
                        'multi_objective': '×¨×‘-×™×¢×“×™', 'total_return': '×ª×©×•××” ×›×•×œ×œ×ª', 'sharpe_ratio': '×™×—×¡ ×©××¨×¤'
                    }
                    objective_key = row.get('objective_function', 'N/A')
                    objective_display = optuna_target_options.get(objective_key, objective_key)
                    
                    scores_str = "N/A"
                    try:
                        scores_list_str = row.get('optuna_scores', '[]')
                        scores_list = json.loads(scores_list_str.replace("'", '"')) if isinstance(scores_list_str, str) else scores_list_str
                        if isinstance(scores_list, list) and scores_list:
                            scores_str = ", ".join([f"{s:.2f}" for s in scores_list])
                    except (json.JSONDecodeError, TypeError):
                        scores_str = str(row.get('optuna_scores', "N/A"))

                    test_accuracy_val = row.get('test_accuracy', 0)
                    test_accuracy_str = f"{test_accuracy_val:.2%}" if isinstance(test_accuracy_val, float) else "N/A"
                    ts = row.get('file_ts');
                    expander_title = f"**×¨×™×¦×”: {row.get('timestamp', 'N/A')}** | ××–×”×”: `{ts}` | ×™×¢×“: {objective_display} | ×¦×™×•×Ÿ: {scores_str} | ×“×™×•×§: {test_accuracy_str}"

                    with st.expander(expander_title):
                        if not ts or ts == 'N/A':
                            st.warning("×œ× × ××¦× ××–×”×” (timestamp) ×¢×‘×•×¨ ×¨×™×¦×” ×–×•.")
                            continue

                        candidate_model_path = models_dir / f'candidate_model_{ts}.pkl'
                        candidate_scaler_path = models_dir / f'candidate_scaler_{ts}.pkl'
                        candidate_config_path = models_dir / f'candidate_model_config_{ts}.json'
                        summary_path = results_dir / f'summary_candidate_{ts}.json'

                        exp_col1, exp_col2, exp_col3 = st.columns([1, 1, 2])
                        with exp_col1:
                            if candidate_model_path.exists() and candidate_config_path.exists():
                                # ×›×¤×ª×•×¨×™× ××—×“ ×œ×™×“ ×”×©× ×™
                                col1, col2 = st.columns(2)
                                with col1:
                                    if st.button(f"ğŸ”„ ×”××©×š", key=f"continue_{ts}", help="×”××©×š ××•×¤×˜×™××™×–×¦×™×” ×¢×œ ×¤×™ ×ª×¦×•×¨×ª ×”××¢×¨×›×ª"):
                                        try:
                                            current_config = load_system_config()
                                            n_trials = current_config['training_params']['n_trials']
                                            
                                            st.success(f"××ª×—×™×œ ×”××©×š ××™××•×Ÿ ×¢× {n_trials} × ×¡×™×•× ×•×ª...")
                                            
                                            # ×”×¨×¦×ª ×”××™××•×Ÿ
                                            run_and_stream_process([sys.executable, "main_trainer.py"], f"×××©×™×š ××™××•×Ÿ ×¢× {n_trials} × ×¡×™×•× ×•×ª...")
                                            st.rerun()
                                        except Exception as e:
                                            st.error(f"×©×’×™××” ×‘×”××©×š ×”××™××•×Ÿ: {e}")
                                
                                with col2:
                                    if st.button(f"ğŸ“Š ×‘×§×˜×¡×˜", key=f"bt_{ts}"):
                                        cmd = [sys.executable, "backtester.py", "--model", str(candidate_model_path), "--scaler", str(candidate_scaler_path), "--config", str(candidate_config_path), "--output_suffix", f"candidate_{ts}"]
                                        run_and_stream_process(cmd, f"××¨×™×¥ ×‘×§×˜×¡×˜ ×¢×œ ××•×“×œ {ts}...")
                                        st.rerun()
                            else:
                                st.caption("×§×‘×¦×™ ××•×“×œ ×—×¡×¨×™×")
                        
                        # ×›×¤×ª×•×¨ ×”×—×œ×ª ×ª×•×¦××•×ª ×¢×œ ×ª×¦×•×¨×ª ×”××¢×¨×›×ª
                        st.markdown("---")
                        apply_col1, apply_col2 = st.columns([2, 1])
                        
                        with apply_col1:
                            if st.button(f"âš™ï¸ ×”×—×œ ×ª×•×¦××•×ª ×¢×œ ×ª×¦×•×¨×ª ×”××¢×¨×›×ª", key=f"apply_{ts}", help="××¢×“×›×Ÿ ××ª system_config.json ×¢× ×”×¤×¨××˜×¨×™× ×”×××•×¤×˜××™×–×¦×™×”"):
                                try:
                                    # ×˜×¢×™× ×ª ×”×ª×¦×•×¨×” ×”× ×•×›×—×™×ª
                                    current_config = load_system_config()
                                    
                                    # ×‘×“×™×§×” ×× ×™×© all_params ×‘× ×ª×•× ×™×
                                    training_summary_path = models_dir / 'training_summary.json'
                                    if training_summary_path.exists():
                                        with open(training_summary_path, 'r', encoding='utf-8') as f:
                                            training_data = json.load(f)
                                        
                                        if 'all_params' in training_data:
                                            # ×©×™××•×© ×‘-all_params ×”×—×“×©
                                            optimized_params = {k: v['value'] for k, v in training_data['all_params'].items() if v['optimized']}
                                        else:
                                            # × ×¤×™×œ×” ×œ×©×™×˜×” ×”×™×©× ×”
                                            optimized_params = training_data.get('best_params', {})
                                        
                                        # ×¢×“×›×•×Ÿ ×”×ª×¦×•×¨×”
                                        updated_count = 0
                                        for param_name, param_value in optimized_params.items():
                                            if param_name in current_config['optuna_param_limits']:
                                                current_config['optuna_param_limits'][param_name]['fixed_value'] = param_value
                                                current_config['optuna_param_limits'][param_name]['optimize'] = False
                                                updated_count += 1
                                        
                                        # ×©××™×¨×ª ×”×ª×¦×•×¨×” ×”××¢×•×“×›× ×ª
                                        with open('system_config.json', 'w', encoding='utf-8') as f:
                                            json.dump(current_config, f, indent=2, ensure_ascii=False)
                                        
                                        st.success(f"âœ… ×¢×•×“×›× ×• {updated_count} ×¤×¨××˜×¨×™× ×‘×ª×¦×•×¨×ª ×”××¢×¨×›×ª. ×”×¤×¨××˜×¨×™× ×”×××•×¤×˜××™×–×¦×™×” ×”×¤×›×• ×œ×§×‘×•×¢×™×.")
                                        
                                        # ×”×¦×’×ª ×”×¤×¨××˜×¨×™× ×©×¢×•×“×›× ×•
                                        if optimized_params:
                                            st.info("**×¤×¨××˜×¨×™× ×©×¢×•×“×›× ×•:**")
                                            for param, value in optimized_params.items():
                                                st.write(f"â€¢ {param}: {value}")
                                            
                                            st.info("ğŸ’¡ ×›×¢×ª ×ª×•×›×œ ×œ××¤×˜××™×–×¦×™×” ×¤×¨××˜×¨×™× ××—×¨×™× ×‘×¢×•×“ ×©××œ×• ×™×™×©××¨×• ×§×‘×•×¢×™×.")
                                        
                                    else:
                                        st.error("×œ× × ××¦× ×§×•×‘×¥ training_summary.json")
                                        
                                except Exception as e:
                                    st.error(f"×©×’×™××” ×‘×”×—×œ×ª ×”×ª×•×¦××•×ª: {e}")
                                    st.code(traceback.format_exc())
                        
                        with apply_col2:
                            if st.button(f"ğŸ—‘ï¸ ××—×§ ×¨×™×¦×”", key=f"delete_{ts}", help="××—×§ ××ª ×›×œ ×”×§×‘×¦×™× ×”×§×©×•×¨×™× ×œ×¨×™×¦×” ×–×•", type="secondary"):
                                try:
                                    # ×¨×©×™××ª ×”×§×‘×¦×™× ×œ××—×™×§×”
                                    files_to_delete = []
                                    
                                    # ×§×‘×¦×™ ××•×“×œ
                                    if candidate_model_path.exists():
                                        files_to_delete.append(candidate_model_path)
                                    if candidate_scaler_path.exists():
                                        files_to_delete.append(candidate_scaler_path)
                                    if candidate_config_path.exists():
                                        files_to_delete.append(candidate_config_path)
                                    
                                    # ×§×‘×¦×™ ×ª×•×¦××•×ª
                                    training_summary_path = models_dir / 'training_summary.json'
                                    if training_summary_path.exists():
                                        files_to_delete.append(training_summary_path)
                                    
                                    backtest_summary_path = models_dir / 'backtest_summary.json'
                                    if backtest_summary_path.exists():
                                        files_to_delete.append(backtest_summary_path)
                                    
                                    # ××—×™×§×ª ×”×§×‘×¦×™×
                                    deleted_count = 0
                                    for file_path in files_to_delete:
                                        try:
                                            file_path.unlink()
                                            deleted_count += 1
                                        except Exception as file_error:
                                            st.warning(f"×œ× × ×™×ª×Ÿ ×œ××—×•×§ {file_path.name}: {file_error}")
                                    
                                    # ××—×™×§×ª ×ª×™×§×™×™×ª ×”××•×“×œ×™× ×× ×”×™× ×¨×™×§×”
                                    try:
                                        if models_dir.exists() and not any(models_dir.iterdir()):
                                            models_dir.rmdir()
                                            st.info(f"× ××—×§×” ×ª×™×§×™×™×ª ×”××•×“×œ×™× ×”×¨×™×§×”: {models_dir.name}")
                                    except Exception:
                                        pass
                                    
                                    if deleted_count > 0:
                                        st.success(f"âœ… × ××—×§×• {deleted_count} ×§×‘×¦×™×")
                                        st.rerun()
                                    else:
                                        st.info("×œ× × ××¦××• ×§×‘×¦×™× ×œ××—×™×§×”")
                                        
                                except Exception as e:
                                    st.error(f"×©×’×™××” ×‘××—×™×§×ª ×”×¨×™×¦×”: {e}")
                                    st.code(traceback.format_exc())

                        with exp_col2:
                            if summary_path.exists():
                                with open(summary_path, encoding='utf-8') as f: summary_data = json.load(f)
                                st.metric("×ª×©×•××ª ×‘×§×˜×¡×˜", f"{summary_data.get('total_return', 0):.2%}", help=f"×™×—×¡ ×©××¨×¤: {summary_data.get('sharpe_ratio', 0):.2f}")
                            else:
                                st.info("××™×Ÿ ×ª×•×¦××•×ª ×‘×§×˜×¡×˜")

                        with exp_col3:
                            st.caption(f"×§×‘×¦×™×: `{candidate_model_path.name}`")

                        st.markdown("---")

                        param_groups = {
                            "×¤×¨××˜×¨×™ ××¡×˜×¨×˜×’×™×” ×•×¡×™×›×•×Ÿ": ['horizon', 'threshold', 'top_n_features', 'risk_per_trade', 'stop_loss_pct', 'take_profit_pct'],
                            "×”×™×¤×¨-×¤×¨××˜×¨×™× (××•×“×œ)": ['learning_rate', 'n_estimators', 'max_depth'],
                            "×‘×™×¦×•×¢×™× (Buy - 1)": ['test_accuracy', 'precision_1', 'recall_1', 'f1_1', 'support_1'],
                            "×‘×™×¦×•×¢×™× (Hold - 0)": ['precision_0', 'recall_0', 'f1_0', 'support_0']
                        }

                        group_cols = st.columns(len(param_groups))

                        for i, (group_title, group_keys) in enumerate(param_groups.items()):
                            with group_cols[i]:
                                st.subheader(group_title)
                                data_for_df = []
                                for key in group_keys:
                                    if key in row and pd.notna(row[key]) and row[key] != 'N/A':
                                        val = row[key]
                                        display_val = val
                                        if isinstance(val, float):
                                            if key in ['test_accuracy', 'precision_1', 'recall_1', 'f1_1', 'precision_0', 'recall_0', 'f1_0']:
                                                display_val = f"{val:.2%}"
                                            else:
                                                display_val = f"{val:.4f}"
                                        data_for_df.append({"××“×“": param_he_map.get(key, key), "×¢×¨×š": display_val})
                                if data_for_df:
                                    st.table(pd.DataFrame(data_for_df).set_index("××“×“"))

                except Exception as e:
                    st.error(f"×©×’×™××” ×‘×¢×™×‘×•×“ ×¨×™×¦×” {row.get('file_ts', '×œ× ×™×“×•×¢')}: {e}")
                    st.code(traceback.format_exc())

    with tab4:
        st.header(":rocket: ×§×™×“×•× ××•×“×œ×™× (Staging)")
        model_dir = Path('models')
        results_dir = Path('reports/backtest_results')

        champion_model = model_dir / 'champion_model.pkl'
        champion_scaler = model_dir / 'champion_scaler.pkl'
        champion_config = model_dir / 'champion_model_config.json'
        
        candidate_models = sorted(model_dir.glob('candidate_model_*.pkl'), key=os.path.getmtime, reverse=True)
        
        if not candidate_models:
            st.info("×œ× × ××¦× ××•×“×œ ××•×¢××“. ×™×© ×œ×××Ÿ ××•×“×œ ×—×“×© ×ª×—×™×œ×”.")
        else:
            candidate_model_path = candidate_models[0]
            ts = "_".join(candidate_model_path.stem.split('_')[-2:])
            candidate_scaler_path = model_dir / f'candidate_scaler_{ts}.pkl'
            candidate_config_path = model_dir / f'candidate_model_config_{ts}.json'

            st.success(f"× ××¦× ××•×“×œ ××•×¢××“: `{candidate_model_path.name}`")

            def load_summary(path):
                try:
                    with open(path, encoding='utf-8') as f: return json.load(f)
                except (FileNotFoundError, json.JSONDecodeError): return None

            champ_summary = load_summary(results_dir / 'summary_champion.json')
            cand_summary = load_summary(results_dir / f'summary_candidate_{ts}.json')

            col1, col2 = st.columns(2)
            with col1:
                if not champ_summary and champion_model.exists():
                    if st.button("ğŸ“Š ×”×¨×¥ ×‘×§×˜×¡×˜ ×œ××•×“×œ ×”××œ×•×£", key="bt_champ"):
                        cmd = [sys.executable, "backtester.py", "--output_suffix", "champion", "--model", str(champion_model), "--scaler", str(champion_scaler), "--config", str(champion_config)]
                        run_and_stream_process(cmd, "××¨×™×¥ ×‘×§×˜×¡×˜ ×¢×œ ××•×“×œ ×”××œ×•×£...")
                        st.rerun()
            with col2:
                if not cand_summary and candidate_model_path.exists():
                    if st.button("ğŸ“Š ×”×¨×¥ ×‘×§×˜×¡×˜ ×œ××•×“×œ ×”××•×¢××“", key="bt_cand"):
                         cmd = [sys.executable, "backtester.py", "--model", str(candidate_model_path), "--scaler", str(candidate_scaler_path), "--config", str(candidate_config_path), "--output_suffix", f"candidate_{ts}"]
                         run_and_stream_process(cmd, f"××¨×™×¥ ×‘×§×˜×¡×˜ ×¢×œ ××•×¢××“ {ts}...")
                         st.rerun()

            st.subheader("×”×©×•×•××ª ×‘×™×¦×•×¢×™×: Champion vs. Candidate")
            if champ_summary or cand_summary:
                metrics_to_show = ["total_return", "sharpe_ratio", "max_drawdown", "win_rate", "trades", "benchmark_return"]
                metric_names_he = {
                    "total_return": "×ª×©×•××” ×›×•×œ×œ×ª",
                    "sharpe_ratio": "×™×—×¡ ×©××¨×¤",
                    "max_drawdown": "×™×¨×™×“×ª ×¢×¨×š ××™×¨×‘×™×ª",
                    "win_rate": "××—×•×– ×”×¦×œ×—×•×ª",
                    "trades": "××¡×¤×¨ ×¢×¡×§××•×ª",
                    "benchmark_return": "×ª×©×•××ª ×™×™×—×•×¡"
                }
                data = {'××“×“': [metric_names_he.get(m, m) for m in metrics_to_show]}

                def format_metric(s_dict, metric):
                    if not s_dict: return "N/A"
                    val = s_dict.get(metric)
                    if val is None: return "N/A"
                    if metric in ["total_return", "max_drawdown", "win_rate", "benchmark_return"]: return f"{val:.2%}"
                    if isinstance(val, float): return f"{val:.2f}"
                    return val

                data['××œ×•×£'] = [format_metric(champ_summary, m) for m in metrics_to_show]
                data['××•×¢××“'] = [format_metric(cand_summary, m) for m in metrics_to_show]
                st.table(pd.DataFrame(data).set_index('××“×“'))
            else:
                st.warning("×œ× × ××¦××• × ×ª×•× ×™ ×‘×™×¦×•×¢×™× ×œ×”×©×•×•××”. ×™×© ×œ×”×¨×™×¥ ×‘×§×˜×¡×˜×™× ×ª×—×™×œ×”.")

            if cand_summary:
                if st.button("ğŸš€ ×§×“× ××•×“×œ ×–×” ×œ××œ×•×£ (Promote to Champion)", type="primary"):
                    try:
                        # Archive existing champion before overwriting
                        if champion_model.exists():
                            archive_dir = model_dir / 'archive'
                            archive_dir.mkdir(exist_ok=True)
                            ts_archive = datetime.now().strftime('%Y%m%d_%H%M%S')
                            shutil.move(champion_model, archive_dir / f"{champion_model.name}.promoted_away.{ts_archive}")
                            if champion_scaler.exists(): shutil.move(champion_scaler, archive_dir / f"{champion_scaler.name}.promoted_away.{ts_archive}")
                            if champion_config.exists(): shutil.move(champion_config, archive_dir / f"{champion_config.name}.promoted_away.{ts_archive}")

                        shutil.copy(candidate_model_path, champion_model)
                        shutil.copy(candidate_scaler_path, champion_scaler)
                        shutil.copy(candidate_config_path, champion_config)
                        
                        # Also copy the backtest results
                        cand_summary_path = results_dir / f'summary_candidate_{ts}.json'
                        champ_summary_path = results_dir / 'summary_champion.json'
                        if cand_summary_path.exists(): shutil.copy(cand_summary_path, champ_summary_path)

                        st.success("×”××•×“×œ ×§×•×“× ×œ××œ×•×£ ×‘×”×¦×œ×—×”! ×™×© ×œ×”×¤×¢×™×œ ××—×“×© ××ª ×©×¨×ª ×”-API ×•/××• ×”×¡×•×›×Ÿ.")
                        st.balloons()
                        time.sleep(2)
                        st.rerun()
                    except Exception as e:
                        st.error(f"×©×’×™××” ×‘×§×™×“×•× ×”××•×“×œ: {e}")